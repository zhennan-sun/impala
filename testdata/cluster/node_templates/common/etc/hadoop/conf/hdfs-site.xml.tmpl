<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>dfs.namenode.http-address</name>
    <value>0.0.0.0:${HDFS_WEBUI_PORT}</value>
  </property>

  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file://${NODE_DIR}/data/dfs/nn</value>
  </property>

  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file://${NODE_DIR}/data/dfs/dn</value>
  </property>

  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.datanode.address</name>
    <value>127.0.0.1:${DATANODE_PORT}</value>
  </property>

  <property>
    <name>dfs.datanode.http.address</name>
    <value>127.0.0.1:0</value>
  </property>

  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>127.0.0.1:0</value>
  </property>

  <property>
    <name>dfs.datanode.https.address</name>
    <value>0.0.0.0:0</value>
  </property>

  <!-- Configuration to enable disk location metadata -->
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.client.file-block-storage-locations.timeout</name>
    <value>500</value>
  </property>

  <!-- Configurations to enable short circuit reads -->
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>

  <!-- The HDFS local read socket must be in the same dir for all nodes. All the sockets
       will be here. Permissions on the parent dirs are strict. -->
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/lib/hadoop-hdfs/socket._PORT</value>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value>false</value>
  </property>

  <!-- 128MB HDFS block size -->
  <property>
    <name>dfs.block.size</name>
    <value>134217728</value>
  </property>
</configuration>
